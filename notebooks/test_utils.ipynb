{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# Add VLA_DIR to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '../')))\n",
    "# Add LIBERO to PYTHONPATH\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '../external/LIBERO')))\n",
    "from libero.libero import benchmark, get_libero_path\n",
    "from utils.LIBERO_utils import get_task_names, extract_task_info\n",
    "\n",
    "## User specific configurations\n",
    "# TODO: change this into argparse for user input in python file\n",
    "DATASET_NAME = \"libero_spatial\" # \"libero_object\", \"libero_spatial\", \"libero_goal\", \"libero_10\", \"libero_90\"\n",
    "# currently no need to change FILTER_KEY and VERBOSE\n",
    "FILTER_KEY = None  # Set filter key if needed, e.g., \"valid\" for validation\n",
    "VERBOSE = True\n",
    "\n",
    "## Check libero dataset path\n",
    "BENCHMARK_PATH = get_libero_path(\"benchmark_root\")\n",
    "DATASET_BASE_PATH = get_libero_path(\"datasets\")\n",
    "DATASET_PATH_DEMO = os.path.join(DATASET_BASE_PATH, DATASET_NAME)\n",
    "print(\"=====================================\")\n",
    "print(\"LIBERO benchmark root path: \", BENCHMARK_PATH)\n",
    "print(\"LIBERO dataset root path: \", DATASET_BASE_PATH)\n",
    "print(f\"LIBERO demonstration dataset for {DATASET_NAME} path: {DATASET_PATH_DEMO}\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "## Load demonstration dataset\n",
    "# get all task names in the dataset\n",
    "task_names_demo = get_task_names(DATASET_PATH_DEMO)\n",
    "# print(f\"Tasks in the demonstration dataset: {task_names_demo}\")\n",
    "# load demonstration data for each task\n",
    "dataset_demo = {}\n",
    "print(\"Start loading demonstration data for each task...\")\n",
    "print(\"-------------------------------------\")\n",
    "for task_name_demo in task_names_demo:\n",
    "    print(f\"Loading demonstration data for task:\\n {task_name_demo}\")\n",
    "    [language_instruction, actions_batch, images_batch] = extract_task_info(DATASET_PATH_DEMO, task_name_demo, filter_key=FILTER_KEY, verbose=VERBOSE)\n",
    "    dataset_demo[task_name_demo] = [language_instruction, actions_batch, images_batch]\n",
    "    # check if actions_batch and images_batch have the same length\n",
    "    assert actions_batch.shape[0] == images_batch.shape[0], \"Dataset problem: the number of actions and images should be the same!\"\n",
    "    # print dataset information\n",
    "    print(\"Loaded successfully!\")\n",
    "    print(f\"Total demonstrations: {actions_batch.shape[0]}\")\n",
    "    ave_len = np.mean([len(x) for x in actions_batch]) # average length of demonstrations\n",
    "    print(f\"Average demonstration length: {ave_len}\")\n",
    "    action_shape = actions_batch[0][0].shape # action shape\n",
    "    print(f\"Action shape: {action_shape}\")\n",
    "    img_shape = images_batch[0][0].shape # image shape\n",
    "    print(f\"Image shape: {img_shape}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLA_CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
